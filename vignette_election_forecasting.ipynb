{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Bayesian Statistics**"
      ],
      "metadata": {
        "id": "QmYVQVS8DeWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two fundamental philosophies when it comes to statistical inference: frequentist and bayesian perspectives. The frequentist approach interprets probability as the long-run frequency of events across repeated trials and treats parameters as fixed but unknown constants. In contrast, the Bayesian approach views parameters as random variables with associated probability distributions. Initial beliefs about the parameters are combined with the observed data to yield posterior distributions. By formally incorporating prior knowledge, such as historical patterns, expert judgment, or previous datasets, the Bayesian approach produces more stable and realistic estimates, especially when data are limited or noisy. Additionally, it is especially well-suited for scenarios involving continuous data monitoring, since bayesian inference can seamlessly update the posterior estimates as new information becomes available."
      ],
      "metadata": {
        "id": "htqznPGcDllW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Application: Predicting Election Results with Pyro**"
      ],
      "metadata": {
        "id": "hTcOwzCevqzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayesian approaches are a natural fit for election forecasting because they help us integrate what we already know about past elections with whatever fresh polling data we have on hand. By capturing long-term trends and specific state interactions, a Bayesian model can bind everything together rather than considering each state as a separate coin flip. In this situation, we are using Pyro because it allows us to create probabilistic models directly in Python while maintaining access to tools like sampling and inference methods.\n",
        "\n",
        "The concept is straightforward: use previous elections to create a prior assumption about each swing state, then utilize poll data to refine those assumptions, and lastly, run thousands of simulations to determine how frequently Democrats win 270 electoral votes.\n",
        "\n",
        "The model gives an initial probability of around 0.68 that the Democrats will win before any polls are conducted. The 2012 baseline and historical voting trends are reflected in this figure.\n",
        "\n",
        "Using two different forms of polling data, the notebook next generates two posterior predictions:\n",
        "  1. Synthetic Poll (generated from the true 2016 state preferences)\n",
        "\n",
        "  *   A posterior of about 0.58 is produced when the model is given a poll that\n",
        "      reflects the actual underlying 2016 findings. This is a positive indicator. Although the poll only included swing states and contained sampling noise, it demonstrated how the model answered by reducing the likelihood of a Democratic victory while maintaining some uncertainty\n",
        "  2. Scaled Actual 2016 Vote Shares\n",
        "\n",
        "  *   A similar update is obtained when the actual 2016 vote percentages are scaled to the same poll size. In this way, it behaves like a real \"in-cycle\" poll and demonstrates how the model would have changed expectations throughout the course of the campaign.\n",
        "\n"
      ],
      "metadata": {
        "id": "NuGLakFrvpEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Bayes Theorem**"
      ],
      "metadata": {
        "id": "y4kuO4LIDwCo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEbg5I8VqsEG"
      },
      "outputs": [],
      "source": [
        "# This file includes code adapted from Pyro tutorials\n",
        "# Source: https://pyro.ai/examples/elections.html\n",
        "# Licensed under the Apache License, Version 2.0\n",
        "\n",
        "# Simplified Bayesian election model using swing states only\n",
        "# Outputs TWO posterior results:\n",
        "# 1. Using synthetic poll generated from 2016 results\n",
        "# 2. Using actual 2016 vote percentages scaled to poll size\n",
        "\n",
        "!pip install pyro-ppl\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "\n",
        "BASE_URL = \"https://raw.githubusercontent.com/pyro-ppl/datasets/master/us_elections/\"\n",
        "\n",
        "# ============================================================\n",
        "# LOAD DATA\n",
        "# ============================================================\n",
        "\n",
        "electoral_college_votes = pd.read_pickle(BASE_URL + \"electoral_college_votes.pickle\")\n",
        "ec_votes_tensor = torch.tensor(electoral_college_votes.values,\n",
        "                               dtype=torch.float).squeeze()\n",
        "\n",
        "frame = pd.read_pickle(BASE_URL + \"us_presidential_election_data_historical.pickle\")\n",
        "\n",
        "# Historical swing states (2000–2020)\n",
        "swing_states = ['FL','PA','MI','WI','OH','NC','GA','NV', 'CO', 'NH']\n",
        "swing_indices = [frame.index.get_loc(st) for st in swing_states]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PRIOR FROM HISTORICAL DATA\n",
        "# ============================================================\n",
        "\n",
        "results_2012 = torch.tensor(frame[2012].values, dtype=torch.float)\n",
        "prior_mean = torch.log(results_2012[..., 0] / results_2012[..., 1])\n",
        "\n",
        "idx = 2 * torch.arange(10)\n",
        "all_results = torch.tensor(frame.values, dtype=torch.float)\n",
        "logits = torch.log(all_results[..., idx] / all_results[..., idx + 1]).transpose(0, 1)\n",
        "\n",
        "mean = logits.mean(0)\n",
        "sample_cov = (1/(logits.shape[0] - 1)) * (\n",
        "    (logits.unsqueeze(-1) - mean) * (logits.unsqueeze(-2) - mean)\n",
        ").sum(0)\n",
        "\n",
        "prior_covariance = sample_cov + 0.01 * torch.eye(sample_cov.shape[0])\n",
        "prior_dist = dist.MultivariateNormal(prior_mean, covariance_matrix=prior_covariance)"
      ],
      "metadata": {
        "id": "VRXF51W99Qhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block constructs the prior distribution over each state's latent Democratic vs. Republican preference in 2016.\n",
        "\n",
        "Here, we take the Democratic and Republican vote totals from 2012 and convert them into log-odds, which are used as the expected party preference for each state in 2016. 2012 is used as the prior because it is the most recent election before 2016, which in election modeling, the previous result is usually the single best predictor of the next.\n",
        "\n",
        "We then use data from 1976-2012 for covariance, since historical patterns over 40 years reveal more information about the volatility of the state outcomes.\n",
        "\n",
        "We also add regularization to the covariance to avoid overconfidence in the covariance."
      ],
      "metadata": {
        "id": "4kP1DvwEEWPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# NATIONAL OUTCOME FUNCTION\n",
        "# ============================================================\n",
        "\n",
        "def election_winner(alpha_logits):\n",
        "    dem_win_state = (alpha_logits > 0).float()\n",
        "    dem_votes = ec_votes_tensor * dem_win_state\n",
        "    return (dem_votes.sum() >= 270).float()\n"
      ],
      "metadata": {
        "id": "akagkHujEAqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function computes the national election outcome given a vector of state-level log-odds."
      ],
      "metadata": {
        "id": "PHjBKnaRI7hN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# POSTERIOR INFERENCE VIA IMPORTANCE SAMPLING\n",
        "# ============================================================\n",
        "\n",
        "def posterior_win_prob_given_y(y_obs, allocation, num_alpha_samples=5000):\n",
        "    \"\"\"Approximate P(Dem win | observed poll y_obs).\"\"\"\n",
        "    alpha_samples = prior_dist.sample((num_alpha_samples,))\n",
        "    dem_win = torch.stack([election_winner(a) for a in alpha_samples])\n",
        "\n",
        "    binom = dist.Binomial(total_count=allocation, logits=alpha_samples)\n",
        "    log_lik = binom.log_prob(y_obs).sum(-1)\n",
        "\n",
        "    maxlog = log_lik.max()\n",
        "    weights = torch.exp(log_lik - maxlog)\n",
        "\n",
        "    return ((weights * dem_win).sum() / weights.sum()).clamp(1e-6, 1 - 1e-6)"
      ],
      "metadata": {
        "id": "p1qDRTD6EJNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function computes the posterior probability of a Democratic win given poll data. It samples state-level preferences from the prior, checks which scenarios result in a Democratic win, and weights each scenario by how likely it is to produce the observed poll results. The weighted average of these outcomes gives the posterior probability, updating our prior belief based on the poll data."
      ],
      "metadata": {
        "id": "R5d97RXDKCnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# PRIOR DEM WIN PROBABILITY (PRINT THIS)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n==============================================\")\n",
        "print(\"Computing PRIOR distribution…\")\n",
        "print(\"==============================================\")\n",
        "\n",
        "alpha_prior_samples = prior_dist.sample((25000,))\n",
        "prior_wins = torch.stack([election_winner(a) for a in alpha_prior_samples])\n",
        "prior_prob = prior_wins.mean().item()\n",
        "\n",
        "print(f\"\\nPrior probability of DEMOCRATIC win (national): {prior_prob:.4f}\")\n",
        "print(\"\\n==============================================\\n\")\n"
      ],
      "metadata": {
        "id": "bXLMi5UcJkgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c88727d-e653-4b7a-9429-340450745764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================================\n",
            "Computing PRIOR distribution…\n",
            "==============================================\n",
            "\n",
            "Prior probability of DEMOCRATIC win (national): 0.6783\n",
            "\n",
            "==============================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block computes the prior probability of a Democratic win before seeing any poll data. It samples many scenarios from the prior distribution, checks which ones result in a Democratic victory using the election_winner function, and averages these outcomes to estimate the national win probability based solely on historical data and 2012 results."
      ],
      "metadata": {
        "id": "hkzhdniQKIQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# LOAD TRUE 2016 RESULTS\n",
        "# ============================================================\n",
        "\n",
        "test_data = pd.read_pickle(BASE_URL + \"us_presidential_election_data_test.pickle\")\n",
        "results_2016 = torch.tensor(test_data.values, dtype=torch.float)\n",
        "true_alpha_2016 = torch.log(results_2016[..., 0] / results_2016[..., 1])\n"
      ],
      "metadata": {
        "id": "umiVe0BCJlI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the actual 2016 election results for each state and convert them into log-odds to represent the true underlying Democratic versus Republican preference. These values are later used to generate synthetic and real polls for comparison with the model's predictions."
      ],
      "metadata": {
        "id": "He7WxI8eKNuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# POLL SIZE AND ALLOCATION\n",
        "# ============================================================\n",
        "\n",
        "TOTAL_POLL = 1500\n",
        "allocation = torch.zeros(51)\n",
        "per_state = TOTAL_POLL // len(swing_states)\n",
        "\n",
        "for st in swing_states:\n",
        "    allocation[frame.index.get_loc(st)] = per_state\n",
        "\n",
        "# Remainder → Florida\n",
        "allocation[frame.index.get_loc('FL')] += TOTAL_POLL - allocation.sum()\n"
      ],
      "metadata": {
        "id": "eNTVq-h4JqLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block sets up the poll size and how respondents are allocated across states. A total of 1,500 poll respondents is distributed evenly among the swing states, with any remaining respondents added to Florida. This allocation is used to simulate state-level polling data for both synthetic and real 2016 polls."
      ],
      "metadata": {
        "id": "2X1M5w1fKSEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# OPTION 1 — SYNTHETIC POLL GENERATED FROM MODEL\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nGenerating SYNTHETIC poll results based on 2016 true preferences...\\n\")\n",
        "\n",
        "y_synth = torch.zeros(51)\n",
        "\n",
        "for st in swing_states:\n",
        "    idx = frame.index.get_loc(st)\n",
        "    total_polled = allocation[idx]\n",
        "\n",
        "    p_dem = torch.sigmoid(true_alpha_2016[idx])\n",
        "    y_synth[idx] = dist.Binomial(total_count=total_polled, probs=p_dem).sample()\n",
        "\n",
        "# ============================================================\n",
        "# OPTION 2 — ACTUAL 2016 PERCENTAGES AS POLL RESULTS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nGenerating poll using ACTUAL 2016 vote percentages...\\n\")\n",
        "\n",
        "y_real = torch.zeros(51)\n",
        "\n",
        "for st in swing_states:\n",
        "    idx = frame.index.get_loc(st)\n",
        "    total_polled = allocation[idx].item()\n",
        "\n",
        "    dem_votes = results_2016[idx, 0]\n",
        "    rep_votes = results_2016[idx, 1]\n",
        "    total_votes = dem_votes + rep_votes\n",
        "\n",
        "    p_dem = dem_votes / total_votes\n",
        "    y_real[idx] = (p_dem * total_polled).round()\n"
      ],
      "metadata": {
        "id": "rAFE59h8Jq0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b4f8c4-f1b0-4b6b-f5b7-88499799f438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating SYNTHETIC poll results based on 2016 true preferences...\n",
            "\n",
            "\n",
            "Generating poll using ACTUAL 2016 vote percentages...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we generate two types of polls for the swing states. The first, synthetic poll, simulates survey results by sampling from a binomial distribution using the true 2016 state preferences, serving as a sanity check for the model. The second uses the actual 2016 vote percentages scaled to the poll size to create a “realistic” poll, which allows comparison of the model's posterior predictions against the actual election outcomes."
      ],
      "metadata": {
        "id": "buvE12N0KWcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# COMPUTE BOTH POSTERIORS\n",
        "# ============================================================\n",
        "\n",
        "posterior_synth = posterior_win_prob_given_y(y_synth, allocation)\n",
        "posterior_real = posterior_win_prob_given_y(y_real, allocation)"
      ],
      "metadata": {
        "id": "zmoVnXQfJzbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd5c63b8-6227-47c1-a248-9b34728e8fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5776)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we compute the posterior probability of a Democratic win for both the synthetic and actual 2016 polls. Using the posterior_win_prob_given_y function, it updates the prior belief based on the observed poll data, producing posterior estimates that reflect how likely Democrats are to win given either the model-generated or real poll results."
      ],
      "metadata": {
        "id": "wZkxUYZJKa4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusion & Further Reading**"
      ],
      "metadata": {
        "id": "X9_xdQDfyVf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This projects explores a concise yet comprehensive Bayesian election model. The notebook demonstrates how a model may transition from a history-based expectation to a poll-informed prediction by using historical voting data as a multivariate prior, transforming state preferences into log-odds, and updating those beliefs with polling information through importance sampling. Despite only concentrating on swing states and employing a simple binomial likelihood, the model still captures the key trends of the 2016 election: Democrats begin with a strong historical lead, but their prospects decline as poll data that mirror the reality of 2016 are included.\n",
        "\n",
        "The transparency of the entire system is what makes it so helpful. Every assumption is made publicly. You can change the covariance to alter the degree of correlation between states and can even include additional weight for polling errors by baking it in. Due to the underlying components like priors, likelihoods, and sampling being arranged in a structured manner, Pyro makes any future adjustments simple."
      ],
      "metadata": {
        "id": "97X5Hj19yYVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are some natural directions we can take this further if we would like to explore:\n",
        "\n"
      ],
      "metadata": {
        "id": "8bOkZKYAzNAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Enhancing via Monte Carlo Methods**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MaEay-Vs0WNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The notebook uses importance sampling, which is simple and effective for minimal models, but once the model becomes more expressive with more states, parameters, turnout uncertainty, it's important that we bolster our important sampling methods.  The weights become unbalanced, and the majority of the samples contribute little to nothing.\n",
        "By sampling directly from the posterior instead of reweighting previous samples, Monte Carlo methods address this issues. Monte Carlo brings improved scaling where it can handle higher-dimensional posteriors without collapsing. This implies that you may use latent variables to account for poll bias, add further layers, or model all 50 states with assurance. MCMC also provide more accurate uncertainty.\n",
        "The whole form of the distribution is represented by posterior samples from MCMC, not only the \"best-fitting\" portion. This provides more accurate predictions of tail scenarios and correlated changes. MC also bring a more realistic simulation result. Every MCMC draw is a self-consistent \"world\" that honors the revised posterior. You get a more complex set of results when you turn those draws into election simulations, which is exactly how forecasting boutiques create their thousands of simulations.\n"
      ],
      "metadata": {
        "id": "5VHovk-0zgyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Introducing Time Series Structure**\n"
      ],
      "metadata": {
        "id": "RTerAtXy0m-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The election is now treated by the model as a single, static update: one prior, one poll, and one posterior. Polls arrive in a sequence, not all at once, and actual campaigns change over time. This slow progression may be captured by the model if a time-series component is added. One popular method is to represent each state's latent log-odds as a random walk or a basic autoregressive process, in which today's preference is yesterday's preference plus a little, normally distributed change. This promotes transitions over sudden jumps and the model, which has a temporal prior in place, can update the posterior each time fresh polling data comes in, creating a trajectory of state preferences leading up to Election Day. The time-series strucuter also helps in distinguishing actual opinion changes from poll noise, as it favors gradual shifts unless the evidence suggests otherwise. In reality, this transforms the model from a single-step into a model that monitors how uncertainty and voter behavior changes over the course of the campaign."
      ],
      "metadata": {
        "id": "jmek8j5o0vIh"
      }
    }
  ]
}